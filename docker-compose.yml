version: "2"

services:
  namenode:
    image: dslab/hadoop-namenode
    container_name: namenode
    hostname: namenode
    # restart: always
    ports:
      - 9870:9870
      - 9000:9000
    networks:
      hdrs_network:
        ipv4_address: 172.22.0.2
    volumes:
      - hadoop_namenode:/hadoop/dfs/name
    environment:
      - CLUSTER_NAME=test
    env_file:
      - ./hadoop/hadoop.env
    stop_signal: SIGINT

  datanode1:
    image: dslab/hadoop-datanode
    container_name: datanode1
    hostname: datanode1
    networks:
      hdrs_network:
        ipv4_address: 172.22.0.3
    # restart: always
    depends_on:
      - "namenode"
    volumes:
      - hadoop_datanode1:/hadoop/dfs/data
    env_file:
      - ./hadoop/hadoop.env
    stop_signal: SIGINT

  datanode2:
    image: dslab/hadoop-datanode
    container_name: datanode2
    hostname: datanode2
    networks:
      hdrs_network:
        ipv4_address: 172.22.0.4
    # restart: always
    depends_on:
      - "namenode"
    volumes:
      - hadoop_datanode2:/hadoop/dfs/data
    env_file:
      - ./hadoop/hadoop.env
    stop_signal: SIGINT

  zoo1:
    image: dslab/zookeeper
    container_name: zoo1
    # restart: always
    hostname: zoo1
    networks:
      hdrs_network:
        ipv4_address: 172.22.0.5
    env_file:
      - ./zookeeper/zookeeper.env
    environment:
      ZOO_MY_ID: 1
      ZOO_ADMINSERVER_ENABLED: 'false'
      ZOO_SERVERS: server.1=zoo1:2888:3888;2181 server.2=zoo2:2888:3888;2181
    volumes:
      - zoo1_data:/zookeeper/data
    stop_signal: SIGINT

  zoo2:
    image: dslab/zookeeper
    container_name: zoo2
    # restart: always
    hostname: zoo2
    networks:
      hdrs_network:
        ipv4_address: 172.22.0.6
    env_file:
      - ./zookeeper/zookeeper.env
    environment:
      ZOO_MY_ID: 2
      ZOO_ADMINSERVER_ENABLED: 'false'
      ZOO_SERVERS: server.1=zoo1:2888:3888;2181 server.2=zoo2:2888:3888;2181
    volumes:
      - zoo2_data:/zookeeper/data
    stop_signal: SIGINT

  hbase-master:
    image: dslab/hbase-hmaster
    container_name: hbase-master
    hostname: hbase-master
    networks:
      hdrs_network:
        ipv4_address: 172.22.0.7
    # restart: always
    depends_on:
      - "namenode"
      - "datanode1"
      - "datanode2"
      - "zoo1"
      - "zoo2"
    env_file:
      - ./hbase/hbase.env
      - ./zookeeper/zookeeper.env
    environment:
      HBASE_CONF_hbase_zookeeper_quorum: zoo1,zoo2
    ports:
      - 16010:16010
    stop_signal: SIGINT
    volumes:
      - hbase-master_tmp:/opt/hbase-2.3.5/tmp

  hbase-regionserver1:
    image: dslab/hbase-hregionserver
    container_name: hbase-regionserver1
    hostname: hbase-regionserver1
    networks:
      hdrs_network:
        ipv4_address: 172.22.0.8
    # restart: always
    depends_on:
      - "hbase-master"
    env_file:
      - ./hbase/hbase.env
    environment:
      HBASE_CONF_hbase_zookeeper_quorum: zoo1,zoo2
      HBASE_CONF_hbase_regionserver_hostname: hbase-regionserver1
      HDS_CONF_hds_httpserver_port: 8000
    ports:
      - 16030:16030
      - 8000:8000
    stop_signal: SIGINT
    volumes:
      - hbase-regionserver1_tmp:/opt/hbase-2.3.5/tmp

  hbase-regionserver2:
    image: dslab/hbase-hregionserver
    container_name: hbase-regionserver2
    hostname: hbase-regionserver2
    networks:
      hdrs_network:
        ipv4_address: 172.22.0.9
    # restart: always
    depends_on:
      - "hbase-master"
    env_file:
      - ./hbase/hbase.env
    environment:
      HBASE_CONF_hbase_zookeeper_quorum: zoo1,zoo2
      HBASE_CONF_hbase_regionserver_hostname: hbase-regionserver2
      HDS_CONF_hds_httpserver_port: 8001
    ports:
      - 8001:8001
    stop_signal: SIGINT
    volumes:
      - hbase-regionserver2_tmp:/opt/hbase-2.3.5/tmp

  # resourcemanager:
  #   image: dslab/hadoop-resourcemanager
  #   container_name: resourcemanager
  #   restart: always
  #   depends_on:
  #     - "namenode"
  #     - "datanode1"
  #     - "datanode2"
  #   ports:
  #     - 8088:8088
  #   env_file:
  #     - ./hadoop/hadoop.env
  #   stop_signal: SIGINT

  # nodemanager1:
  #   image: dslab/hadoop-nodemanager
  #   container_name: nodemanager
  #   restart: always
  #   depends_on:
  #     - "resourcemanager"
  #   ports:
  #     - 8042:8042
  #   env_file:
  #     - ./hadoop/hadoop.env
  #   stop_signal: SIGINT

  # historyserver:
  #   image: dslab/hadoop-historyserver
  #   container_name: historyserver
  #   restart: always
  #   depends_on:
  #     - "dcfs-master"
  #   volumes:
  #     - hadoop_historyserver:/hadoop/yarn/timeline
  #   env_file:
  #     - ./hadoop/hadoop.env
  #   stop_signal: SIGINT

  rabbitmq:
    image: rabbitmq:3.9.10-management
    container_name: rabbitmq
    # restart: always
    hostname: rabbitmq
    networks:
      hdrs_network:
        ipv4_address: 172.22.0.10
    ports:
      - 15672:15672
    stop_signal: SIGINT
    volumes:
      - ./rabbitmq/rabbitmq.conf:/etc/rabbitmq/rabbitmq.conf

  dcfs-master:
    image: dslab/dcfs-master
    container_name: dcfs-master
    hostname: dcfs-master
    networks:
      hdrs_network:
        ipv4_address: 172.22.0.11
    # restart: always
    depends_on:
      - "namenode"
      - "datanode1"
      - "datanode2"
      - "rabbitmq"
    ports:
      - 8088:8088
    env_file:
      - ./hadoop/hadoop.env
    environment:
      - YARN_CONF_yarn_resourcemanager_hostname=dcfs-master
      - YARN_CONF_yarn_resourcemanager_address=dcfs-master:8032
      - YARN_CONF_yarn_resourcemanager_scheduler_address=dcfs-master:8030
      - YARN_CONF_yarn_resourcemanager_resource__tracker_address=dcfs-master:8031
    stop_signal: SIGINT
    volumes:
      - ./dcfs/dcfs-share:/dcfs-share

  dcfs-worker1:
    image: dslab/dcfs-worker
    container_name: dcfs-worker1
    hostname: dcfs-worker1
    networks:
      hdrs_network:
        ipv4_address: 172.22.0.12
    # restart: always
    depends_on:
      - "dcfs-master"
    ports:
      - 8042:8042
    env_file:
      - ./hadoop/hadoop.env
    environment:
      - 'YARN_CONF_yarn_nodemanager_webapp_address=$${yarn.nodemanager.hostname}:8042'
      - YARN_CONF_yarn_resourcemanager_hostname=dcfs-master
      - YARN_CONF_yarn_resourcemanager_address=dcfs-master:8032
      - YARN_CONF_yarn_resourcemanager_scheduler_address=dcfs-master:8030
      - YARN_CONF_yarn_resourcemanager_resource__tracker_address=dcfs-master:8031
    stop_signal: SIGINT
    volumes:
      - ./dcfs/dcfs-share:/dcfs-share

  dcfs-worker2:
    image: dslab/dcfs-worker
    container_name: dcfs-worker2
    hostname: dcfs-worker2
    networks:
      hdrs_network:
        ipv4_address: 172.22.0.13
    # restart: always
    depends_on:
      - "dcfs-master"
    ports:
      - 8043:8043
    env_file:
      - ./hadoop/hadoop.env
    environment:
      - 'YARN_CONF_yarn_nodemanager_webapp_address=$${yarn.nodemanager.hostname}:8043'
      - YARN_CONF_yarn_resourcemanager_hostname=dcfs-master
      - YARN_CONF_yarn_resourcemanager_address=dcfs-master:8032
      - YARN_CONF_yarn_resourcemanager_scheduler_address=dcfs-master:8030
      - YARN_CONF_yarn_resourcemanager_resource__tracker_address=dcfs-master:8031
    stop_signal: SIGINT
    volumes:
      - ./dcfs/dcfs-share:/dcfs-share
  
  flask:
    image: dslab/flask
    container_name: flask
    hostname: flask
    networks:
      hdrs_network:
        ipv4_address: 172.22.0.14
    # restart: always
    depends_on:
      - "rabbitmq"
      - "dcfs-master"
    env_file:
      - ./web/flask/flask.env
    ports:
      - 5000:5000
    stop_signal: SIGINT
    volumes:
      - ./web/flask/flask-share:/flask-share
      - ./web/flask/hello.py:/hello.py
      - ./web/flask/static:/static
      - ./web/flask/template:/template

volumes:
  hadoop_namenode:
  hadoop_datanode1:
  hadoop_datanode2:
  # hadoop_historyserver:
  zoo1_data:
  zoo2_data:
  hbase-master_tmp:
  hbase-regionserver1_tmp:
  hbase-regionserver2_tmp:

networks:
  hdrs_network:
    driver: bridge
    ipam:
      driver: default
      config:
        - subnet: 172.22.0.0/16